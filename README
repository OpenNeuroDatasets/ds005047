**Summary**

Facial expression is among the most natural methods for human beings to convey their emotional information in daily life. Although the neural mechanism of facial expression has been extensively studied employing lab-controlled images and a small number of lab-controlled video stimuli, how the human brain processes natural facial expressions still needs to be investigated. To our knowledge, this type of data specifically on large number of natural facial expression videos is currently missing. We describe here the natural Facial Expressions Dataset (NFED), a fMRI dataset including responses to 1,320 short (3-second) natural facial expression video clips. These video clips is annotated with three types of labels: emotion, gender, and ethnicity, along with accompanying metadata. We validate that the dataset has good quality within and across participants and, notably, can capture temporal and spatial stimuli features. NFED provides researchers with fMRI data for understanding of the visual processing of large number of natural  facial expression videos.

**Data record**
he data were organized according to the Brain-Imaging-Data-Structure (BIDS) Specification version 1.7.0 and can be accessed from the OpenNeuro public repository (accession number: ds005047).The “sub-<subID>” folders store the raw data of each participant. The pre-processed volume data were saved as the “derivatives/pre-processed_volume_data/sub-<subID>” folders, while the pre-processed surface data were saved in the “derivatives/volumetosurface/sub-<subID>” folders.

*Stimulus*
Distinct folders store the stimuli for distinct fMRI experiments: "stimuli/face-video", "stimuli/floc", and "stimuli/prf" (Fig. 2b). The category labels and metadata corresponding to video stimuli are stored in the "videos-stimuli_category_metadata.tsv”. The “videos-stimuli_description.json” file describes  category and metadata information of video stimuli(Fig. 2b).

*Raw MRI data*
 Each participant's folder is comprised of 11 session folders: “sub-<subID>/ses-anat”, “sub-<subID>/ses-<sesID>” (Fig. 2c). The “ses-anat” folder comprises one folder, named “anat”. The “ses-<sesID>” folder comprises “fmap”and “func” folders. A “sub-<subID>_ses-<sesID>_scans.tsv” file stores the scan information for a scan session. The task events were saved as a “sub-<subID>/func/sub-<subID>_ses-<sesID>_task-<taskID>_run-<runID>_events.tsv” file for each run.

*Freesurfer recon-all*
The results of reconstructing the cortical surface were saved as “recon-all-FreeSurfer/sub-<subID>” folders (Fig. 2f). The process of the  recon-all and the information of  FreeSurfer are stored in “recon-all-freesurfer_data_description.json”.

*Pre-processed volume data from pre-processing*
 We have conducted GLMsingle on the data of the main experiment. There is a file named “sub--<subID>_ses-<sesID>_task-<taskID>_betas_FITHRF_GLMDENOISE_RR.hdf5” which contains the betas from a scanning session. A “sub-<subID>_ses-<sesID>_task-<taskID>_FRACvalue.hdf5” file  stores the the fractional ridge regression regularization level selected for individual voxels of a scanning session. A “sub-<subID>_ses-<sesID>_task-<taskID>_HRFindex.hdf5” file stores the 1-index of the best Hemodynamic Response Function（HRF） of a scanning session. The file named "sub-<subID>_ses-<sesID>_task-<taskID>_HRFindexrun.hdf5" stores HRF index which are segregated by run. A “sub-<subID>_ses-<sesID>_task-<taskID>_R2.hdf5” file stores the model accuracy. A “sub-<subID>_ses-<sesID>_task-<taskID>_R2run.hdf5” file stores R2 which is segregated by run.
A “sub-<subID>_ses-<sesID>_task-<taskID>_mean.mat” file stores the mean of the GLM analysis data for the pRF and fLoc experiments (Fig. 2g). The process of the  GLM analysis are stored in “surface-based_GLM_analysis_data_description.json”.

*Preprocessed surface-based data*
The pre-processed surface-based data were stored in a file named “volumetosurface/sub-<subID>/ses-<sesID>/sub-<subID>_ses-<sesID>_task-<taskID>_run-<index>_hemi-lh/rh.surfacedata.gii” for each run (Fig. 2e). The process of the pre-processing based on surface is stored in “volumetosurface_data_description.json”.

*Brain activation data from surface-based GLM analyses*
  We have conducted GLMsingle on the data of the main experiment. There is a file named “sub--<subID>_ses-<sesID>_task-<taskID>_betas_FITHRF_GLMDENOISE_RR.hdf5” which contains the betas from a scanning session. A “sub-<subID>_ses-<sesID>_task-<taskID>_FRACvalue.hdf5” file  stores the the fractional ridge regression regularization level selected for individual voxels of a scanning session. A “sub-<subID>_ses-<sesID>_task-<taskID>_HRFindex.hdf5” file stores the 1-index of the best Hemodynamic Response Function（HRF） of a scanning session. The file named "sub-<subID>_ses-<sesID>_task-<taskID>_HRFindexrun.hdf5" stores HRF index which are segregated by run. A “sub-<subID>_ses-<sesID>_task-<taskID>_R2.hdf5” file stores the model accuracy. A “sub-<subID>_ses-<sesID>_task-<taskID>_R2run.hdf5” file stores R2 which is segregated by run.
A “sub-<subID>_ses-<sesID>_task-<taskID>_mean.mat” file stores the mean of the GLM analysis data for the pRF and fLoc experiments (Fig. 2g). The process of the  GLM analysis are stored in “surface-based_GLM_analysis_data_description.json”

*The technical validation of the NFED*
The all code and the data required to run the code were saved as “derivatives/validation/code” folder. The results of technical validation were saved as “derivatives/validation/results” folder.








